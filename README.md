# ğŸ¤– LLM App â€” OpenAI + Local (Ollama) Chatbot

This is a full-stack chatbot app that supports:

- ğŸ§  **OpenAI (GPT-3.5, GPT-4, GPT-4 Turbo)**
- ğŸ–¥ï¸ **Local LLMs via [Ollama](https://ollama.com)**
- ğŸ’¬ Markdown + syntax-highlighted responses
- ğŸ’¬ Bubble-style chat UI with copyable code blocks
- ğŸ› Model + provider selection
- ğŸ—‚ Sidebar chat history with delete & new chat
- ğŸ–± One-click `.bat` launcher for full stack

## ğŸ— Folder Structure

```
llm-app/
â”œâ”€â”€ backend/               # FastAPI backend
â”‚   â”œâ”€â”€ app/               # Includes main.py, llm_providers.py
â”‚   â”œâ”€â”€ venv/              # Python virtual environment
â”‚   â””â”€â”€ .env               # Contains OpenAI + Hugging Face API keys
â”œâ”€â”€ frontend/              # React UI
â”œâ”€â”€ local_model_server.py  # (Optional) Flask mock server
â”œâ”€â”€ start_llm_app.bat      # ğŸ–± One-click launcher (3 terminals)
```

## âš™ Prerequisites

- Node.js (v18+ recommended)
- Python 3.10+
- Ollama (for local LLMs) â†’ https://ollama.com/download
- [OpenAI API key](https://platform.openai.com/account/api-keys)

## ğŸ§ª Setup Instructions

### ğŸ”¹ 1. Clone the Repo

```bash
git clone https://github.com/your-username/llm-app.git
cd llm-app
```

### ğŸ”¹ 2. Backend Setup

```bash
cd backend
python -m venv venv
venv\Scripts\activate  # use source venv/bin/activate on Mac/Linux
pip install -r requirements.txt
```

Create a `.env` in `backend/`:

```
OPENAI_API_KEY=your-openai-key
HF_API_KEY=your-huggingface-key  # optional
```

### ğŸ”¹ 3. Frontend Setup

```bash
cd frontend
npm install
```

### ğŸ”¹ 4. Ollama Setup

```bash
ollama run llama2
```

Or preload other models:

```bash
ollama pull mistral
ollama pull gemma
```

### ğŸ–± 5. Launch the App (One click)

Just double-click:

```
start_llm_app.bat
```

It will:
- Run FastAPI backend
- Start local model
- Open React frontend

## ğŸ§  Features

- âœ… Model selection (OpenAI / Local)
- âœ… Markdown + syntax-highlighted answers
- âœ… Bubble chat UI with "Copy" buttons
- âœ… Chat history + delete + new chat
- âœ… Dark mode
- âœ… Typing animation (`â ‹â ™â ¹...`)
- âœ… Local model via Ollama (real-time inference)

## ğŸ§± Coming Next (Optional Ideas)

- ğŸ” Real-time streaming responses from Ollama
- ğŸ’¾ Export chat to Markdown/Text
- ğŸ“Š Token usage & cost tracking
- ğŸŒ Deploy to Vercel + Render (for OpenAI only mode)
